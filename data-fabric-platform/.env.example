# ================================
# Data Fabric Platform Configuration
# ================================

# Environment
ENVIRONMENT=development  # development, staging, production
LOG_LEVEL=INFO
DEBUG=false

# ================================
# Azure Configuration
# ================================
# Azure Storage
AZURE_STORAGE_ACCOUNT_NAME=your_storage_account
AZURE_STORAGE_ACCOUNT_KEY=your_storage_key
AZURE_CONTAINER_NAME=data-fabric
AZURE_ADLS_GEN2_ENDPOINT=https://your_storage_account.dfs.core.windows.net

# Azure Data Factory
AZURE_SUBSCRIPTION_ID=your_subscription_id
AZURE_RESOURCE_GROUP=data-fabric-rg
AZURE_DATA_FACTORY_NAME=your_adf_name
AZURE_TENANT_ID=your_tenant_id
AZURE_CLIENT_ID=your_client_id
AZURE_CLIENT_SECRET=your_client_secret

# Azure Databricks
AZURE_DATABRICKS_WORKSPACE_URL=https://adb-xxxxxxxxx.azuredatabricks.net
AZURE_DATABRICKS_TOKEN=your_databricks_token
AZURE_DATABRICKS_CLUSTER_ID=your_cluster_id

# Azure Synapse
AZURE_SYNAPSE_WORKSPACE=your_synapse_workspace
AZURE_SYNAPSE_SQL_POOL=your_sql_pool

# Azure Key Vault
AZURE_KEY_VAULT_NAME=your_key_vault
AZURE_KEY_VAULT_URL=https://your_key_vault.vault.azure.net/

# ================================
# AWS Configuration
# ================================
# AWS Credentials
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_DEFAULT_REGION=us-east-1
AWS_ACCOUNT_ID=your_account_id

# AWS S3
AWS_S3_BUCKET=data-fabric-bucket
AWS_S3_BRONZE_PREFIX=bronze/
AWS_S3_SILVER_PREFIX=silver/
AWS_S3_GOLD_PREFIX=gold/

# AWS Glue
AWS_GLUE_DATABASE=data_fabric_db
AWS_GLUE_CATALOG_ID=your_catalog_id

# AWS EMR
AWS_EMR_CLUSTER_ID=your_emr_cluster_id
AWS_EMR_MASTER_DNS=your_emr_master_dns

# AWS Redshift
AWS_REDSHIFT_HOST=your_redshift_cluster.region.redshift.amazonaws.com
AWS_REDSHIFT_PORT=5439
AWS_REDSHIFT_DATABASE=data_fabric
AWS_REDSHIFT_USER=admin
AWS_REDSHIFT_PASSWORD=your_password

# AWS Secrets Manager
AWS_SECRETS_MANAGER_REGION=us-east-1

# ================================
# Hadoop Configuration
# ================================
HADOOP_NAMENODE_HOST=namenode.example.com
HADOOP_NAMENODE_PORT=9000
HADOOP_WEBHDFS_PORT=50070
HADOOP_USER=hadoop
HDFS_BASE_PATH=/data-fabric

# Hive
HIVE_SERVER_HOST=hive-server.example.com
HIVE_SERVER_PORT=10000
HIVE_DATABASE=data_fabric

# YARN
YARN_RESOURCE_MANAGER_HOST=resourcemanager.example.com
YARN_RESOURCE_MANAGER_PORT=8032

# ================================
# Apache Spark Configuration
# ================================
SPARK_MASTER=local[*]  # local[*], yarn, or spark://master:7077
SPARK_APP_NAME=DataFabricPlatform
SPARK_EXECUTOR_MEMORY=4g
SPARK_EXECUTOR_CORES=2
SPARK_DRIVER_MEMORY=2g
SPARK_SHUFFLE_PARTITIONS=200
SPARK_SQL_ADAPTIVE_ENABLED=true

# Delta Lake
DELTA_LAKE_ENABLED=true
DELTA_LOG_CACHE_SIZE=1000

# ================================
# Apache Airflow Configuration
# ================================
AIRFLOW_HOME=/opt/airflow
AIRFLOW_CORE_DAGS_FOLDER=/opt/airflow/dags
AIRFLOW_CORE_EXECUTOR=LocalExecutor
AIRFLOW_DATABASE_SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow

# ================================
# Database Configuration
# ================================
# PostgreSQL (Metadata Store)
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DATABASE=data_fabric_metadata
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

# MongoDB (Catalog)
MONGODB_HOST=localhost
MONGODB_PORT=27017
MONGODB_DATABASE=data_catalog
MONGODB_USER=catalog_user
MONGODB_PASSWORD=catalog_password

# ================================
# Data Lake Configuration
# ================================
# Local Development Paths
LOCAL_DATA_PATH=/data
LOCAL_RAW_PATH=/data/raw
LOCAL_PROCESSED_PATH=/data/processed
LOCAL_STAGING_PATH=/data/staging
LOCAL_ARCHIVE_PATH=/data/archive

# Bronze-Silver-Gold Layers
BRONZE_LAYER_PATH=bronze
SILVER_LAYER_PATH=silver
GOLD_LAYER_PATH=gold

# ================================
# Data Quality Configuration
# ================================
DATA_QUALITY_ENABLED=true
QUALITY_CHECK_MODE=strict  # strict, warn, disabled
ANOMALY_DETECTION_ENABLED=true
DATA_PROFILING_SAMPLE_SIZE=10000

# ================================
# Migration Configuration
# ================================
MIGRATION_BATCH_SIZE=10000
MIGRATION_MAX_RETRIES=3
MIGRATION_CHECKPOINT_ENABLED=true
MIGRATION_CHECKPOINT_PATH=/checkpoints

# ================================
# Monitoring & Logging
# ================================
# Prometheus
PROMETHEUS_ENABLED=true
PROMETHEUS_PORT=9090

# Grafana
GRAFANA_ENABLED=true
GRAFANA_PORT=3000
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=admin

# Logging
LOG_FORMAT=json  # json, text
LOG_FILE_PATH=/logs/data-fabric.log
LOG_ROTATION_SIZE=100MB
LOG_RETENTION_DAYS=30

# ================================
# Security Configuration
# ================================
# Encryption
ENCRYPTION_ENABLED=true
ENCRYPTION_ALGORITHM=AES-256
KMS_KEY_ID=your_kms_key_id

# Authentication
AUTH_ENABLED=true
AUTH_METHOD=oauth2  # oauth2, basic, api_key

# Network
PRIVATE_ENDPOINT_ENABLED=false
VPN_ENABLED=false

# ================================
# Performance Tuning
# ================================
# Parallel Processing
MAX_WORKERS=4
ASYNC_ENABLED=true

# Caching
CACHE_ENABLED=true
CACHE_TTL_SECONDS=3600
CACHE_BACKEND=redis  # redis, memory

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# ================================
# Feature Flags
# ================================
ENABLE_AZURE=true
ENABLE_AWS=true
ENABLE_HADOOP=true
ENABLE_STREAMING=true
ENABLE_DATA_CATALOG=true
ENABLE_AUTO_DISCOVERY=true
ENABLE_LINEAGE_TRACKING=true
